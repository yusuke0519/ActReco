{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: CNN with Pytorch using Opp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "# dataset\n",
    "from actreco.datasets.opportunityc import Opportunity\n",
    "from actreco.sampling import sampling\n",
    "\n",
    "# modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choice_func(train=True, initial_test_state=0):\n",
    "    i = [0]  # nb call\n",
    "    def choice():\n",
    "        i[0] += 1\n",
    "        if train is True:\n",
    "            return np.random.choice\n",
    "        \n",
    "        r = np.random.RandomState(initial_test_state+i[0])\n",
    "        return r.choice\n",
    "    return choice()\n",
    "\n",
    "\n",
    "def batch_generator(x_list, y_list, batch_size, l_sample, train=True, nb_iter=1, categorical=False, seed=0):\n",
    "    choice = choice_func(train, initial_test_state=seed)\n",
    "    \n",
    "    nb_sample = sum([x.shape[0] for x in x_list])\n",
    "    idx_set = set(range(nb_sample))\n",
    "    nb_seen_sample = 0\n",
    "    for x in x_list:\n",
    "        nb_seen_sample += x.shape[0]\n",
    "        idx_set -= set(range(nb_seen_sample-l_sample+1, nb_seen_sample+1))\n",
    "    valid_idx = list(idx_set)\n",
    "    \n",
    "    x = np.concatenate(x_list)\n",
    "    y = np.concatenate(y_list)\n",
    "    \n",
    "    for i in range(nb_iter):\n",
    "        start = choice(valid_idx, batch_size)\n",
    "        X = sampling(x, 'clips', dtype='np', start=start, l_sample=l_sample)[..., np.newaxis].swapaxes(1, 3)\n",
    "        Y = sampling(y, 'clips', dtype='np', start=start, l_sample=l_sample)\n",
    "        Y = np.concatenate([Y.sum(axis=1), np.ones((batch_size, 1))], axis=-1).argmax(axis=-1)\n",
    "        if categorical is not False:\n",
    "            Y = np.eye(categorical)[Y]\n",
    "        yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = Opportunity(userID='S1,S2,S3')\n",
    "x_train_list = train_set.get('X')\n",
    "y_train_list = train_set.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = Opportunity(userID='S4')\n",
    "x_test_list = test_set.get('X')\n",
    "y_test_list = test_set.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VanilaCNN(nn.Module):\n",
    "    def __init__(self, l_sample, nb_modal, nb_in_filter, nb_filter_list, kw, nb_unit, nb_out):\n",
    "        super(VanilaCNN, self).__init__()\n",
    "        self.l_sample = l_sample\n",
    "        self.nb_modal = nb_modal\n",
    "        self.nb_conv = len(nb_filter_list)\n",
    "        \n",
    "        if isinstance(kw, int):\n",
    "            kw = [kw] * self.nb_conv\n",
    "        assert len(nb_filter_list) == len(kw)\n",
    "        nb_filter_list = [nb_in_filter] + nb_filter_list\n",
    "        \n",
    "        self.kw = kw\n",
    "        self.nb_filter_list = nb_filter_list\n",
    "\n",
    "        convs = []\n",
    "        for i in range(self.nb_conv):\n",
    "            convs.append(nn.Conv2d(nb_filter_list[i], nb_filter_list[i+1], (1, kw[i])))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.fc1 = nn.Linear(self.conv_output_shape(), nb_unit)\n",
    "        self.fc2 = nn.Linear(nb_unit, nb_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = F.max_pool2d(F.relu(conv(x)), (1, 2))\n",
    "            dropout = nn.Dropout2d(0.5)\n",
    "            # x = dropout(x)\n",
    "        x = x.view(-1, self.conv_output_shape())\n",
    "        x = F.dropout(self.fc1(x), 0.5)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def conv_output_shape(self):\n",
    "        length = self.l_sample\n",
    "        for i in range(self.nb_conv):\n",
    "            length = int((length - self.kw[i] + 1) /2)\n",
    "        return length * self.nb_filter_list[-1] * self.nb_modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_modal_dim = 2\n",
    "nb_modal = train_set.nb_modal\n",
    "nb_out = train_set.nb_class\n",
    "\n",
    "kw = 3\n",
    "nb_filter_list = [50, 40, 20]\n",
    "nb_in_filter = 1\n",
    "drop_rate = 0.5\n",
    "nb_unit = 400\n",
    "\n",
    "batch_size = 128\n",
    "l_sample = 30\n",
    "interval = int(l_sample) * 0.5\n",
    "\n",
    "nb_iter = 100\n",
    "report_each = 10\n",
    "\n",
    "model = VanilaCNN(l_sample=l_sample, nb_modal=nb_modal, nb_in_filter=1, nb_filter_list=nb_filter_list, kw=kw, nb_unit=nb_unit, nb_out=nb_out).cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (13 of 100) |###                     | Elapsed Time: 0:00:00 ETA:  0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 samples, 10 batch \t Loss: 2.420109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% (25 of 100) |######                  | Elapsed Time: 0:00:01 ETA:  0:00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560 samples, 20 batch \t Loss: 1.739100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35% (35 of 100) |########                | Elapsed Time: 0:00:01 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840 samples, 30 batch \t Loss: 1.623932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% (44 of 100) |##########              | Elapsed Time: 0:00:01 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 samples, 40 batch \t Loss: 1.472973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% (54 of 100) |############            | Elapsed Time: 0:00:02 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 samples, 50 batch \t Loss: 1.580431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63% (63 of 100) |###############         | Elapsed Time: 0:00:02 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680 samples, 60 batch \t Loss: 1.419703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73% (73 of 100) |#################       | Elapsed Time: 0:00:03 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8960 samples, 70 batch \t Loss: 1.634461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84% (84 of 100) |####################    | Elapsed Time: 0:00:03 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240 samples, 80 batch \t Loss: 1.649884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94% (94 of 100) |######################  | Elapsed Time: 0:00:04 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11520 samples, 90 batch \t Loss: 1.794142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (99 of 100) |####################### | Elapsed Time: 0:00:04 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800 samples, 100 batch \t Loss: 1.670719\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "p = ProgressBar(max_value=nb_iter)\n",
    "gen = batch_generator(x_train_list, y_train_list, batch_size, l_sample, train=True, nb_iter=nb_iter, categorical=False)\n",
    "for batch_idx, (X, y) in enumerate(gen):\n",
    "    batch_idx += 1\n",
    "    tX = Variable(torch.from_numpy(X.astype('float32')), requires_grad=False).cuda()\n",
    "    ty = Variable(torch.LongTensor(y), requires_grad=False).cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(tX)\n",
    "    \n",
    "    loss = criterion(output, ty)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % report_each == 0:\n",
    "        print(\"{} samples, {} batch \\t Loss: {:.6f}\".format(batch_idx * batch_size, batch_idx, loss.data[0]))\n",
    "    p.update(batch_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def test(model, x_list, y_list, l_sample, nb_iter=1, batch_size=2048):\n",
    "    model.eval()\n",
    "    test_gen = batch_generator(x_train_list, y_train_list, batch_size, l_sample, train=False, nb_iter=nb_iter, categorical=False, seed=0)\n",
    "    y_list = []\n",
    "    py_list = []\n",
    "    for X, y in test_gen:\n",
    "        tX = Variable(torch.from_numpy(X.astype('float32')), requires_grad=False).cuda()\n",
    "        py = model(tX).max(1)[1].data.cpu().numpy().reshape(-1)\n",
    "        y_list.append(y)\n",
    "        py_list.append(py)\n",
    "    \n",
    "    y = np.concatenate(y_list)\n",
    "    py = np.concatenate(py_list)\n",
    "    print(metrics.accuracy_score(y, py))\n",
    "    print(metrics.f1_score(y, py, average='macro'))\n",
    "    print(metrics.precision_score(y, py, average=None))\n",
    "    print(metrics.recall_score(y, py, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n",
      "0.0415923945336\n",
      "[ 0.        0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.        0.\n",
      "  0.546875]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "test(model, x_test_list, y_test_list, l_sample, nb_iter=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras model for comparison\n",
    "# which is much slower than pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBA\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "if keras.__version__ >= '2.0.0':\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Convolution2D, Dropout, Activation, Flatten\n",
    "    from keras.layers import MaxPooling2D\n",
    "\n",
    "    from keras.optimizers import SGD\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(50, kernel_size=(1, 3), input_shape=[1, nb_modal, l_sample]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(Convolution2D(40, (1, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(Convolution2D(20, (1, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_unit))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = SGD(lr=0.01, momentum=0.5)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    p = ProgressBar(max_value=report_each)\n",
    "    gen = batch_generator(x_train_list, y_train_list, batch_size, l_sample, train=True, nb_iter=nb_iter, categorical=train_set.nb_class)\n",
    "    for batch_idx, (X, y) in enumerate(gen):\n",
    "        batch_idx += 1\n",
    "        loss = model.train_on_batch(X, y)\n",
    "        if batch_idx % report_each == 0:\n",
    "            print(\"Seen {} samples, {} batch \\t Loss: {:.6f}\".format(batch_idx * batch_size, batch_idx, float(loss)))\n",
    "            p.update(report_each)\n",
    "        else:\n",
    "            p.update((batch_idx % report_each))\n",
    "else:\n",
    "    print(\"TBA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
